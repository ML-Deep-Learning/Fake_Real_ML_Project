{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FAKE & REAL NEWS DETECTION USING DEEP LEARNING.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "crNFUF7BagOn"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import re\n",
        "from wordcloud import WordCloud "
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7esg62ldVFM"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,LSTM,Conv1D,MaxPool1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,accuracy_score"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_PyfnQRh-S5"
      },
      "source": [
        "# **Exploring Fake News**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NABHZnIBo8Tu"
      },
      "source": [
        "fake= pd.read_csv('https://raw.githubusercontent.com/ML-Deep-Learning/Fake_Real_news_dataset/main/Fake.csv')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEWwhmvWww2Q"
      },
      "source": [
        "fake.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lOFXQUGw4vo"
      },
      "source": [
        "fake.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbeDGGzqxHMr"
      },
      "source": [
        "fake['subject'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOcA6qnIx4YW"
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='subject',data=fake)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnp6Ni_Rysj4"
      },
      "source": [
        "# **WordCloud**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jjPgI7Zy1X4"
      },
      "source": [
        "text=' '.join(fake['text'].tolist())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuVw4WOZ1zDm"
      },
      "source": [
        "wordcloud = WordCloud(width=2000,height=1100,margin=10).generate(text)\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFeNb-X64fYV"
      },
      "source": [
        "# **Exploring Real Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-nti9LY4qDV"
      },
      "source": [
        "real = pd.read_csv('https://raw.githubusercontent.com/ML-Deep-Learning/Fake_Real_news_dataset/main/True.csv')"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibthtGjU5dOF"
      },
      "source": [
        "text =' '.join(real['text'].tolist())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGhAA0FL5sTP"
      },
      "source": [
        "wordcloud = WordCloud(width=2000,height=1100,margin=10).generate(text)\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqqwx12kO6eM"
      },
      "source": [
        "# Cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfSa7KCAPKRN"
      },
      "source": [
        "unknown_publishers = []\n",
        "for index , row in enumerate(real.text.values):\n",
        "  try:\n",
        "    record = row.split('-', maxsplit=1)\n",
        "    record[1]\n",
        "\n",
        "    assert(len(record[0])<120)\n",
        "  except:\n",
        "      unknown_publishers.append(index)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mOtLK9GSeK6"
      },
      "source": [
        "len(unknown_publishers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xKcfCNISkYE"
      },
      "source": [
        "real.iloc[unknown_publishers].text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sToHo-OzTFm8"
      },
      "source": [
        "publisher = []\n",
        "tmp_text = []\n",
        "\n",
        "for index , row in enumerate(real.text.values):\n",
        "  if index in unknown_publishers:\n",
        "    tmp_text.append(row)\n",
        "    publisher.append('Unknown')\n",
        "\n",
        "  else:\n",
        "    record = row.split('-' , maxsplit=1)\n",
        "    publisher.append(record[0].strip())\n",
        "    tmp_text.append(record[1].strip())\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9eofR8PZYP0"
      },
      "source": [
        "real['publisher']= publisher\n",
        "real['text'] = tmp_text"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQghyPp-aR2n"
      },
      "source": [
        "real.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOTpb1f6afYK"
      },
      "source": [
        "real.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfTBe5oDb8N0"
      },
      "source": [
        "empty_fake_index = [index for index, text in enumerate(fake.text.tolist()) if str(text).strip()==\"\"]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y39oiRxMc0-E"
      },
      "source": [
        "fake.iloc[empty_fake_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHHRoEWwdOc5"
      },
      "source": [
        "real['text'] = real['title'] + \" \" + real['text']\n",
        "fake['text'] = fake['title'] + \" \" + fake['text']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpKuOShudsdB"
      },
      "source": [
        "real['text'] = real['text'].apply(lambda x: str(x).lower())\n",
        "fake['text'] = fake['text'].apply(lambda x: str(x).lower())"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZId3SbCQejga"
      },
      "source": [
        "# Preprocessing Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKMGgyM9esXr"
      },
      "source": [
        "real['class'] = 1\n",
        "fake['class'] = 0"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97GC36HZfVmr"
      },
      "source": [
        "real = real[['text', 'class' ]]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5DDL_8LflY4"
      },
      "source": [
        "fake = fake[['text', 'class' ]]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro-QdN0cgBwN"
      },
      "source": [
        "data = real.append(fake, ignore_index=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIfMzjSQhseJ"
      },
      "source": [
        "# https://github.com/laxmimerit/preprocess_kgptalkie"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPgn9pvJhy1C"
      },
      "source": [
        "!pip install spacy==2.2.3\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install beautifulsoup4==4.9.1\n",
        "!pip install textblob==0.15.3\n",
        "!pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git --upgrade --force-reinstall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-uRTePOinRR"
      },
      "source": [
        "import preprocess_kgptalkie as ps"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrnYmoXPit3u"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: ps.remove_special_chars(x))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrKn9xS7kL6v"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzoKnXddklUv"
      },
      "source": [
        "# Vectorization - Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0n_uMWLkyFx"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j11TohYKlZtP"
      },
      "source": [
        "y = data['class'].values"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcpUOSc9llGD"
      },
      "source": [
        "X = [d.split() for d in data['text'].tolist()]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2ajTR_tmE7E"
      },
      "source": [
        "type(X[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRrqYVzQmLZI"
      },
      "source": [
        "print(X[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4r4gh2anB8J"
      },
      "source": [
        "DIM=100\n",
        "w2v_model = gensim.models.Word2Vec(sentences=X , size=DIM, window=10, min_count=1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cux7PBgUo8Ep"
      },
      "source": [
        "len(w2v_model.wv.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2UkNp4AqeU3"
      },
      "source": [
        "w2v_model.wv.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTdPXYp7pQIo"
      },
      "source": [
        "w2v_model.wv['usa']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MdUf9mDpySd"
      },
      "source": [
        "w2v_model.wv.most_similar('india')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNk4FbN1rO-d"
      },
      "source": [
        "tokeniser = Tokenizer()\n",
        "tokeniser.fit_on_texts(X)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT8NTfsWsMte"
      },
      "source": [
        "X= tokeniser.texts_to_sequences(X)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B74ZBsFMsbXb"
      },
      "source": [
        "tokeniser.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld60h3oku2cg"
      },
      "source": [
        "plt.hist([len(x) for x in X], bins= 700)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qKmlRWzvmcz"
      },
      "source": [
        "nos = np.array([len(x) for x in X])\n",
        "len(nos[nos>1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq32LUQIxW0C"
      },
      "source": [
        "maxlen = 1000\n",
        "X = pad_sequences(X, maxlen=maxlen)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwOIqR7fxpIe"
      },
      "source": [
        "len(X[101])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK_tPIlExwh-"
      },
      "source": [
        "vocab_size = len(tokeniser.word_index) + 1\n",
        "vocab = tokeniser.word_index"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyFAKBz3yFcm"
      },
      "source": [
        "def get_weight_matrix(model):\n",
        "  weight_matrix = np.zeros((vocab_size,DIM))\n",
        "\n",
        "  for word, i in vocab.items():\n",
        "    weight_matrix[i] = model.wv[word]\n",
        "\n",
        "  return weight_matrix  "
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDljwnRwzwoN"
      },
      "source": [
        "embedding_vectors = get_weight_matrix(w2v_model)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VMM4X855_JE"
      },
      "source": [
        "embedding_vectors.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aESNfpyG6GbR"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim=DIM, weights = [embedding_vectors],input_length=maxlen,trainable= True))\n",
        "model.add(LSTM(units=128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss= 'binary_crossentropy', metrics='accuracy')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N18Ehm7_8jRM"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkAVFHDR8vwM"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOoLZhs39M6q"
      },
      "source": [
        "model.fit(X_train,y_train,validation_split=0.3, epochs=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud9voPaA-jdb"
      },
      "source": [
        "y_pred = (model.predict(X_test) >=0.5).astype(int)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPZBIikw_GL7"
      },
      "source": [
        "accuracy_score(y_test , y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZOCRw54DFge"
      },
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOGv_BlJF6aV"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVyijNqQE2aF"
      },
      "source": [
        "# Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RhMboGEE6oi",
        "outputId": "63a88d12-e542-47c1-aafe-aa6f4bb7c11f"
      },
      "source": [
        "x=['House panel asks Trump ex-top aide Bannon to testify: Bloomberg']\n",
        "x= tokeniser.texts_to_sequences(x)\n",
        "x= pad_sequences(x, maxlen=maxlen)\n",
        "(model.predict(x) >=0.5).astype(int)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    }
  ]
}